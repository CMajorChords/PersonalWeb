import streamlit as st
from openai import OpenAI
from PyPDF2 import PdfReader
from io import BytesIO


@st.cache_data(
    show_spinner="è¯»å–PDFä¸­...æ–‡ä»¶é‡Œçš„å­—æ•°è¶…è¿‡15kä¸ªtokenæ—¶ï¼ŒAIå°±è¯»ä¸ä¸‹å»äº†" if st.session_state.language == "ä¸­æ–‡" else "Reading PDF...When the number of words in the file exceeds 15k tokens, AI will not read it")
def read_pdf(uploaded_file):
    pdf_reader = PdfReader(BytesIO(uploaded_file.getvalue()))
    pdf_text = "è¿™æ˜¯ä¸€ä¸ªpdfæ–‡ä»¶é‡Œçš„å†…å®¹:" if st.session_state.language == "ä¸­æ–‡" else "This is the content in a PDF file:"
    for page in pdf_reader.pages:
        pdf_text += page.extract_text() or ""
    pdf_text = pdf_text.replace("\n", " ").replace("\r", " ").replace("\t", " ")
    pdf_text = ' '.join(pdf_text.split())
    return pdf_text


def select_model(model_name: str):
    model_options = {
        ":rainbow[gpt 3.5 turbo]": "gpt-3.5-turbo-0125",
        ":rainbow[gpt 4]": "gpt-4",
    }
    return model_options[model_name]


def AI_assistant():
    # æ˜¾ç¤ºæ ‡é¢˜
    st.subheader("funğŸ’¤ AI", anchor=False)
    st.write(
        "ä½¿ç”¨åŸºäºtransformeræ¶æ„çš„å¤§è¯­è¨€AIæ¨¡å‹" if st.session_state.language == "ä¸­æ–‡" else "Use transformer-based large language "
                                                                                        "AI model")
    model_chosen = select_model(st.radio(
        "é€‰æ‹©AIæ¨¡å‹" if st.session_state.language == "ä¸­æ–‡" else "Select AI model",
        [":rainbow[gpt 3.5 turbo]", ":rainbow[gpt 4]"],
        captions=["æœ€å¤š60æ¬¡æé—®/å°æ—¶", "æœ€å¤š3æ¬¡æé—®/å¤©"] if st.session_state.language == "ä¸­æ–‡" else [
            "Up to 60 questions/hour",
            "Up to 3 questions/day"],
        horizontal=True,
        label_visibility="collapsed",
    ))
    # è®¾ç½®openaiçš„api_key
    client = OpenAI(
        api_key=st.secrets["OPENAI_API_KEY"],
        base_url="https://api.chatanywhere.cn/v1",  # https://api.chatanywhere.cn/v1https://api.chatanywhere.com.cn
    )
    # åˆå§‹åŒ–å¯¹è¯
    if "messages" not in st.session_state:
        st.session_state.messages = []
    # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºPDFå·²ç»ä¸Šä¼ 
    if "pdf_uploaded" not in st.session_state:
        st.session_state.pdf_uploaded = False
    # ä¸Šä¼ pdfæ–‡ä»¶
    uploaded_file = st.file_uploader(
        "å¯ä»¥ä¸Šä¼ PDFæ–‡ä»¶ï¼Œæ ¹æ®æ–‡ä»¶å†…å®¹è¿›è¡Œå¯¹è¯" if st.session_state.language == "ä¸­æ–‡" else "You can upload PDF files and chat based on "
                                                                                           "the content of the file",
        type=["pdf"],
        help="å¯ä»¥ä¸Šä¼ æ–‡çŒ®ã€ä¹¦ç±ç­‰PDFæ–‡ä»¶" if st.session_state.language == "ä¸­æ–‡" else "You can upload PDF files such as literature "
                                                                                      "and books",
    )
    if uploaded_file and not st.session_state.pdf_uploaded:
        pdf_text = read_pdf(uploaded_file)
        st.session_state["pdf_text"] = {"role": "user", "content": pdf_text}
        st.session_state.pdf_uploaded = True  # è®¾ç½®æ ‡å¿—ï¼Œè¡¨ç¤ºPDFå·²ç»ä¸Šä¼ 
    # ä»session_stateä¸­è·å–ç”¨æˆ·è¾“å…¥çš„ä¿¡æ¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    # # æ¥æ”¶ç”¨æˆ·è¾“å…¥
    try:
        if prompt := st.chat_input(
                "å¯¹AIè¯´ç‚¹ä»€ä¹ˆ..." if st.session_state.language == "ä¸­æ–‡" else "Say something to AI..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)
            with st.chat_message("assistant"):
                if "pdf_text" in st.session_state:
                    all_messages = [st.session_state.pdf_text] + st.session_state.messages
                else:
                    all_messages = st.session_state.messages
                stream = client.chat.completions.create(
                    model=model_chosen,
                    messages=[
                        {"role": m["role"], "content": m["content"]}
                        for m in all_messages
                    ],
                    stream=True,
                    prompt=st.session_state.messages[-1]["content"],
                )
                response = st.write_stream(stream)
            st.session_state.messages.append({"role": "assistant", "content": response})
    except:
        # å¦‚æœpdfå­˜åœ¨çš„è¯ï¼Œæç¤ºpdfæ–‡ä»¶å¤ªå¤§äº†
        if st.session_state.pdf_uploaded:
            st.error(
                "pdfæ–‡ä»¶å¤ªå¤§äº†ï¼ŒAIä¸æƒ³è¯»äº†" if st.session_state.language == "ä¸­æ–‡" else "The PDF file is too large, AI "
                                                                                       "doesn't want to read it")
        else:
            st.error(
                "AIä¸æƒ³ç†ä½ äº†ï¼Œåˆ·æ–°é¡µé¢é‡æ–°å¼€å§‹å§" if st.session_state.language == "ä¸­æ–‡" else "AI doesn't want to talk to you, "
                                                                                              "refresh the apps "
                                                                                              "to start over")
