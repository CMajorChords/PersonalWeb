
<h2 style='pointer-events: none;'>分类任务的网络结构</h2>
<h3 style='pointer-events: none;'>1.前馈神经网络</h3>

简单实现一个mnist手写数字识别的前馈神经网络
<h4 style='pointer-events: none;'>数据集</h4>

mnist数据集是一个手写数字识别的数据集，包含60000个训练样本和10000个测试样本，每个样本是一个28*28的灰度图像，对应一个0-9的数字标签。
```
import torch
import torch.nn as nn
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt

# MNIST dataset
train_dataset = torchvision.datasets.MNIST(root='./data/MNIST',
                                           train=True,
                                           download=True,
                                           transform=transforms.ToTensor()
                                           )
test_dataset = torchvision.datasets.MNIST(root='./data/MNIST',
                                            train=False,
                                            transform=transforms.ToTensor()
                                            )
# Data loader
train_loader = torch.utils.data.DataLoader(dataset=train_dataset,
                                           batch_size=batch_size,
                                           shuffle=True
                                           )
test_loader = torch.utils.data.DataLoader(dataset=test_dataset,
                                            batch_size=batch_size,
                                            shuffle=False
                                            )
```
<h4 style='pointer-events: none;'>模型</h4>

包含两个隐藏层的前馈神经网络，每个隐藏层包含256个神经元，激活函数为ReLU，输出层包含10个神经元，激活函数为Softmax。
```
class NeuralNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, num_classes)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        out = self.relu(out)
        out = self.fc3(out)
        # out = self.softmax(out) # CrossEntropyLoss() has included softmax
        return out
        
model = NeuralNet(input_size, hidden_size, num_classes)
```
<h4 style='pointer-events: none;'>损失函数和优化器</h4>

损失函数使用交叉熵损失函数，优化器使用Adam优化器。
```
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
```
<h4 style='pointer-events: none;'>训练</h4>

```
total_step = len(train_loader)
for epoch in range (num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        # Reshape images to (batch_size, input_size)
        images = images.reshape(-1, 28*28) # -1 means the size is inferred
        # Forward pass
        outputs = model(images)
        loss = criterion(outputs, labels)
        # Backward and optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if (i+1) % 100 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
```
<h4 style='pointer-events: none;'>测试</h4>

```
# Test the model
# In test phase, we don't need to compute gradients (for memory efficiency)
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images.reshape(-1, 28*28)
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum()
    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))
```
<h3 style='pointer-events: none;'>2.交叉熵与softmax回归</h3>
<h4 style='pointer-events: none;'>交叉熵</h4>

交叉熵一般比较适合衡量两个概率分布的差异性，它是信息论中的一个概念，用来衡量两个概率分布之间的距离，交叉熵越小，两个概率分布越接近。交叉熵的定义如下： 
$$
H(p,q)=-\sum_{x}p(x)logq(x)
$$
```
import numpy as np

def cross_entropy(actual, predicted):
    return - np.sum(actual * np.log(predicted))
```
交叉熵损失函数计算的是两个概率分布之间的距离，而不是真实标签和预测值之间的距离，所以交叉熵损失函数在分类任务中比均方误差损失函数更加合适。
一个用交叉熵损失函数的例子：
```
# One hot encoding
Y = np.array([1, 0, 0])
Y_pred_good = np.array([0.7, 0.2, 0.1])
Y_pred_bad = np.array([0.1, 0.3, 0.6])
l1 = cross_entropy(Y, Y_pred_good)
l2 = cross_entropy(Y, Y_pred_bad)
```
<h4 style='pointer-events: none;'>softmax回归</h4>

softmax回归是一个多分类模型，它的输出是一个概率分布。假设有K个类别，
那么对于一个输入样本x，它属于第k类的概率为：
$$
P(y=k|x)=\frac{exp(x^Tw_k)}{\sum_{i=1}^Kexp(x^Tw_i)}
$$
<h4 style='pointer-events: none;'>pytorch实现</h4>

```
import torch
import torch.nn as nn
import torch.nn.functional as F

loss = nn.CrossEntropyLoss()
Y = torch.tensor([0])
# nsamples x nclasses = 1 x 4
Y_pred_good = torch.tensor([[2.0, 1.0, 0.1, 0.5]])
Y_pred_bad = torch.tensor([[0.5, 1.0, 2.1, 0.3]])

l1 = loss(Y_pred_good, Y)
l2 = loss(Y_pred_bad, Y)

print(l1.item())
print(l2.item())

# get predicted classes
_, predictions1 = torch.max(Y_pred_good, 1)
_, predictions2 = torch.max(Y_pred_bad, 1)
print(predictions1)
print(predictions2)
```
<h4 style='pointer-events: none;'>一个简单的多分类任务</h4>

```
import torch
import torch.nn as nn

# Multiclass problem
class NeuralNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NeuralNet, self).__init__()
        self.linear1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.linear2 = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        out = self.linear1(x)
        out = self.relu(out)
        out = self.linear2(out)
        # no activation and no softmax at the end
        return out
        # if it's a binary classification problem, we can use sigmoid
        # y_pred = torch.sigmoid(out)
        # return y_pred

model = NeuralNet(input_size=28*28, hidden_size=5, num_classes=3)
criterion = nn.CrossEntropyLoss() # applies softmax for us
# criterion = nn.BCELoss() # for binary classification
```
<h3 style='pointer-events: none;'>3.softmax回归的简洁实现</h3>

softmax函数可以将输出变换成合法的概率分布。softmax回归适用于分类问题。
softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持 可导的性质。
为了完成这一目标，我们首先对每个未规范化的预测求幂，这样可以确保输出非负。 为了确保最终输出的概率值总和为1，我们再让每个求幂后的结果除以它们的总和：
$$
\hat{\mathbf{y}}=\operatorname{softmax}(\mathbf{o}) \quad \text { 其中 } \quad \hat{y}_j=\frac{\exp \left(o_j\right)}{\sum_k \exp \left(o_k\right)}
$$
这里的$\hat{y}_j$是预测为$y_j$的概率，而$\mathbf{o}$是我们希望得到的未规范化的预测，所以这里的softmax实际上起到了一个归一化的作用。
<h4 style='pointer-events: none;'>图像分类数据集（Fashion-MNIST）</h4>

```
import torch
import torchvision
from torch.utils import data
from torchvision import transforms
from d2l import torch as d2l

d2l.use_svg_display()
```

Fashion-MNIST数据集每张图片是一个每个输入图像的高度和宽度均为28像素。 数据集由灰度图像组成，其通道数为1。 


```
# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，
# 并除以255使得所有像素的数值均在0～1之间
trans = transforms.ToTensor()
mnist_train = torchvision.datasets.FashionMNIST(
    root="../data", train=True, transform=trans, download=True)
mnist_test = torchvision.datasets.FashionMNIST(
    root="../data", train=False, transform=trans, download=True)
mnist_train[0][0].shape
# 结果是torch.Size([1, 28, 28])，说明数据集中的图像通道数为1，高和宽均为28像素
```

    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../data\FashionMNIST\raw\train-images-idx3-ubyte.gz
    

    100%|██████████| 26421880/26421880 [00:04<00:00, 5308358.83it/s] 
    

    Extracting ../data\FashionMNIST\raw\train-images-idx3-ubyte.gz to ../data\FashionMNIST\raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../data\FashionMNIST\raw\train-labels-idx1-ubyte.gz
    

    100%|██████████| 29515/29515 [00:00<00:00, 42763.88it/s]
    

    Extracting ../data\FashionMNIST\raw\train-labels-idx1-ubyte.gz to ../data\FashionMNIST\raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../data\FashionMNIST\raw\t10k-images-idx3-ubyte.gz
    

    100%|██████████| 4422102/4422102 [00:25<00:00, 172989.88it/s] 
    

    Extracting ../data\FashionMNIST\raw\t10k-images-idx3-ubyte.gz to ../data\FashionMNIST\raw
    
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
    Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gz
    

    100%|██████████| 5148/5148 [00:00<00:00, 1416909.05it/s]

    Extracting ../data\FashionMNIST\raw\t10k-labels-idx1-ubyte.gz to ../data\FashionMNIST\raw
    

    
    




    torch.Size([1, 28, 28])



label是一个数字，它代表了图像所代表的服装类别，我们可以通过下面的函数来获取数字标签所代表的服装类别的名称。


```
def get_fashion_mnist_labels(labels):  #@save
    """返回Fashion-MNIST数据集的文本标签。"""
    text_labels = [
        "t-shirt", "trouser", "pullover", "dress", "coat", "sandal", "shirt",
        "sneaker", "bag", "ankle boot"
    ]
    return [text_labels[int(i)] for i in labels]
```

看看训练集和测试集有多大。


```
len(mnist_train), len(mnist_test)
```




    (60000, 10000)



建立一个看图函数，方便我们查看数据集中的图像。


```
def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
    """绘制图像列表"""
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            # 图片张量
            ax.imshow(img.numpy())
        else:
            # PIL图片
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes

# 取一个批量的样本，一共18张图像
X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));
```
<h4 style='pointer-events: none;'>softmax回归模型 </h4>

```
from torch import nn
batch_size = 256
train_iter = data.DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)
```

初始化模型


```
net = nn.Sequential(nn.Flatten(), nn.Linear(784, 10))
# 初始化权重
def init_weights(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, std=0.01)

net.apply(init_weights);
```

优化与损失函数


```
loss = nn.CrossEntropyLoss()
trainer = torch.optim.SGD(net.parameters(), lr=0.1)
```

训练


```
num_epochs = 10
for epoch in range(num_epochs):
    for X, y in train_iter:
        l = loss(net(X), y)
        trainer.zero_grad()
        l.mean().backward() # 求平均损失
        trainer.step()
    l = loss(net(X), y)
    print(f'epoch {epoch + 1}, loss {l:f}')
```
<h3 style='pointer-events: none;'>4.使用CNN进行分类任务</h3>
<h4 style='pointer-events: none;'>CNN</h4>

首先我们弄清楚卷积的概念是什么，卷积公式长这个样子：  
$$  
y(t)=\int_{-\infty}^{\infty} x(\tau) h(t-\tau) d \tau
$$
具体的含义可以在[这个视频](https://www.youtube.com/watch?v=D641Ucd_xuw)里找到。
值得注意的是，这个公式可以理解为，如果一个系统，输入是不稳定的，输出是稳定的，那我们就可以用卷积求系统的存量。  
举个例子，其实用时段单位线求地面径流就是一个卷积运算，
每个时刻的输入的净雨量是不稳定的，但不管你输入多少净雨量，对这些雨量进行的操作都是固定的，
即用这些净雨量乘以一个单位线，然后求和，单位线是时不变的，是一个固定的函数，这样我们自然就可以求出地面径流。
自然，求得的每个时刻的地面径流其实都是这个时刻地面径流的存量，该时刻的地面径流由之前所有时刻的净雨量决定。
这里的单位线就是卷积核，卷积核是一个固定的函数，卷积核的作用就是对输入的数据进行一个固定的操作。  
至此我们理解了狭义上的卷积，但CNN的卷积操作其实更广义，我们刚刚理解的是在时域上发生的操作，
但如果这里的$t$指的不是时域而是距离呢，时间距离、空间距离，whatever，
而且这里的输入函数可能并不是一维的，卷积操作的公式可以泛化为：
$$
y(x,y)=\int_{-\infty}^{\infty} \int_{-\infty}^{\infty} x(\tau_1,\tau_2) h(x-\tau_1,y-\tau_2) d \tau_1 d \tau_2
$$
xy其实就是指的图像中卷积核中心对应的那个像素点坐标，

|         | 1st column | 2nd column | 3rd column |
|---------|--------------|-------------|--------------|
| **1st row** | $f(x-1,y-1)$ | $f(x-1,y)$  | $f(x-1,y+1)$ |
| **2nd row** | $f(x,y-1)$   | $f(x,y)$    | $f(x,y+1)$   |
| **3rd row** | $f(x+1,y-1)$ | $f(x+1,y)$  | $f(x+1,y+1)$ |

由于像素点并不是连续的，所以这里的积分可以理解为求和，这样我们就可以得到一个卷积核，这个卷积核的作用就是对输入的数据进行一个固定的操作。
其实这里的$h$函数并不是一个卷积核，而是一个卷积核倒过来180度的函数，也就是卷积核省略了旋转这个操作。
<h4 style='pointer-events: none;'>CNN进行图像分类</h4>

CNN主要用于捕捉图像的局部特征，
为什么能够用于降雨径流模拟这种时间序列建模我也没搞懂，
但他有的时候确实起作用，
说明这里的卷积运算有什么我们不清楚的特性，
能够捕捉时间序列上的前后关系，
这里我们先暂时实现一下CNN对图像的分类，
这一类工作可能在之后的利用遥感影像进行降雨径流模拟中有用。  
```
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
import numpy as np
```
首先，如果有GPU的话，我们就用GPU，因为这是一个图像分类问题，GPU会快很多。
```
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
```
<h4 style='pointer-events: none;'>设置一下超参数  </h4>

```
num_epochs = 200
batch_size = 4
learning_rate = 0.001
```
<h4 style='pointer-events: none;'>Dataset和Dataloader</h4>

```
# 这里的transform包含了两个操作：ToTensor()将图片转换为Tensor，Normalize()做归一化
# the transform contains two operations: ToTensor() converts the image to Tensor, Normalize() does normalization
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                             download=True, transform=transform)

test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                            download=True, transform=transform)

train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,
                                              shuffle=True)
                                                       
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,
                                                shuffle=False)
                               
classes = ('plane', 'car', 'bird', 'cat',
             'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```
<h4 style='pointer-events: none;'>模型</h4>

```
class ConvNet(nn.Module):
    def __init__(self, num_classes=10):
        super(ConvNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5) # 3 chanels, 6 kernels, kernel size 5
        self.pool = nn.MaxPool2d(2, 2) # kernel size 2, stride 2
        self.conv2 = nn.Conv2d(6, 16, 5) # 6 chanels, 16 kernels, kernel size 5
        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 16*5*5 is the size of the output of the second convolution layer
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, num_classes) # num_classes is 10
        
    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x))) # 32*32*3 -> 28*28*6 -> 14*14*6
        x = self.pool(F.relu(self.conv2(x))) # 14*14*6 -> 10*10*16 -> 5*5*16
        x = x.view(-1, 16 * 5 * 5) # 5*5*16 -> 400
        x = F.relu(self.fc1(x)) # 400 -> 120
        x = F.relu(self.fc2(x)) # 120 -> 84
        x = self.fc3(x) # 84 -> 10
        return x
model = ConvNet()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
```
<h4 style='pointer-events: none;'>训练</h4>

```
for epoch in range(num_epochs):
    for i, (images, labels) in enumerate(train_loader):
        images = images
        labels = labels
        outputs = model(images)
        loss = criterion(outputs, labels)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        if (i+1) % 1000 == 0:
            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' 
                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))
```
<h4 style='pointer-events: none;'>测试</h4>

```
model.eval()
with torch.no_grad():
    correct = 0
    total = 0
    for images, labels in test_loader:
        images = images
        labels = labels
        outputs = model(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))
```

